{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN/LHeSERGJNr39sooGeqk4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyGSFZ9X6-nw","executionInfo":{"status":"ok","timestamp":1685100248147,"user_tz":-540,"elapsed":21047,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"bc228444-fd6e-4e75-b6f8-d9752b89e0d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import os.path\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from sklearn.metrics import r2_score\n","\n","import os\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.models import Sequential,load_model,save_model\n","from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D\n","from keras.layers import BatchNormalization\n","from keras.optimizers import Adam"],"metadata":{"id":"WCt2BN-t5qgR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Age Estimation"],"metadata":{"id":"Fo6q8nh_6pXa"}},{"cell_type":"code","source":["# image_dir = Path('/content/drive/MyDrive/AI/.kaggle/20-50') #tell python in which directory the training images are.\n","image_dir = Path('/content/drive/MyDrive/AI/.kaggle/20-50')"],"metadata":{"id":"RcVMcM_N5swz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filepaths = pd.Series(list(image_dir.glob(r'**/*.jpg')), name='Filepath').astype(str)\n","ages = pd.Series(filepaths.apply(lambda x: os.path.split(os.path.split(x)[0])[1]), name='Age').astype(np.int32)\n","\n","images = pd.concat([filepaths, ages], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)\n"],"metadata":{"id":"7K-nEWg35vLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_df = images.sample(20000, random_state=1).reset_index(drop=True)\n","\n","train_df, test_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)"],"metadata":{"id":"iVJe71UW5xYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255,\n","    validation_split=0.2\n",")\n","\n","test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255\n",")"],"metadata":{"id":"54HATMxY5y6R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images = train_generator.flow_from_dataframe(\n","    dataframe=train_df,\n","    x_col='Filepath', # kepek\n","    y_col='Age', # becsülendő életkorok\n","    target_size=(120, 120), # egy kép mérete\n","    color_mode='rgb', # 3 csatornás képek, RGB\n","    class_mode='raw', # mivel a célváltozónk int típusú és nem object\n","    batch_size=32,\n","    shuffle=True,\n","    seed=42,\n","    subset='training'\n",")\n","\n","val_images = train_generator.flow_from_dataframe(\n","    dataframe=train_df,\n","    x_col='Filepath',\n","    y_col='Age',\n","    target_size=(120, 120),\n","    color_mode='rgb',\n","    class_mode='raw',\n","    batch_size=32,\n","    shuffle=True,\n","    seed=42,\n","    subset='validation'\n",")\n","\n","test_images = test_generator.flow_from_dataframe(\n","    dataframe=test_df,\n","    x_col='Filepath',\n","    y_col='Age',\n","    target_size=(120, 120),\n","    color_mode='rgb',\n","    class_mode='raw',\n","    batch_size=32,\n","    shuffle=False\n",")"],"metadata":{"id":"6wwRnmLS52Dk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = tf.keras.Input(shape=(120, 120, 3))\n","x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\n","x = tf.keras.layers.MaxPool2D()(x)\n","x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n","x = tf.keras.layers.MaxPool2D()(x)\n","x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","x = tf.keras.layers.Dense(64, activation='relu')(x)\n","x = tf.keras.layers.Dense(64, activation='relu')(x)\n","outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n","\n","age_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","\n","age_model.compile(\n","    optimizer='adam',\n","    loss='mse'\n",")\n","\n","history = model.fit(\n","    train_images,\n","    validation_data=val_images,\n","    epochs=5,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor='val_loss',\n","            patience=5,\n","            restore_best_weights=True\n","        )\n","    ]\n",")"],"metadata":{"id":"xBqDttRw54LP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Gender Estimation"],"metadata":{"id":"4EMxinPV6tK5"}},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","      rotation_range=25,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')"],"metadata":{"id":"5xUzvTkN6wci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","target_size = (64, 64)\n","input_shape=(64, 64, 3)\n","seed=1337\n","adam = 0.001\n","fre= -20\n","FC = 2048\n","E = 1\n","patience = 3\n","verbose = 1\n","factor = 0.50\n","min_lr = 0.0001\n","steps_per_epoch=256\n","validation_steps=256\n","epochs=8"],"metadata":{"id":"ermvgY_a651D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_datagen = ImageDataGenerator( rescale = 1.0/255)\n","\n","train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/AI/.kaggle/Dataset/Train',\n","                                                    batch_size =batch_size ,\n","                                                    class_mode = 'binary',\n","                                                    seed=seed,\n","                                                    target_size = target_size )     \n","\n","validation_generator =  test_datagen.flow_from_directory( '/content/drive/MyDrive/AI/.kaggle/Dataset/Validation',\n","                                                          batch_size  = batch_size,\n","                                                          class_mode  = 'binary',\n","                                                          seed=seed,\n","                                                          target_size = target_size)"],"metadata":{"id":"hLi-W4RO69Rn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = tf.keras.applications.VGG16(input_shape=input_shape,include_top=False,weights=\"imagenet\")"],"metadata":{"id":"flosc8FO6_tW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Freezing Layers\n","\n","for layer in base_model.layers[:fre]:\n","    layer.trainable=False"],"metadata":{"id":"uKX3xnwj7FwU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Building Model\n","gender_model=Sequential()\n","gender_model.add(base_model)\n","gender_model.add(layers.Dropout(.2))\n","\n","gender_model.add(Conv2D(512, (3, 3),strides=(1,1), activation='relu', padding='same'))\n","gender_model.add(BatchNormalization())\n","gender_model.add(layers.Dropout(.1))\n","gender_model.add(Conv2D(128, (3, 3),strides=(1,1), activation='relu', padding='same'))\n","gender_model.add(BatchNormalization())\n","gender_model.add(layers.Dropout(.1))\n","gender_model.add(Conv2D(384, (3, 3),strides=(1,1), activation='relu', padding='same'))\n","gender_model.add(BatchNormalization())\n","gender_model.add(layers.Dropout(.1))\n","gender_model.add(Conv2D(384, (3, 3),strides=(1,1), activation='relu', padding='same'))\n","gender_model.add(BatchNormalization())\n","gender_model.add(layers.Dropout(.1))\n","gender_model.add(Conv2D(500, (3, 3),strides=(1,1), activation='relu', padding='same'))\n","gender_model.add(BatchNormalization())\n","gender_model.add(MaxPooling2D(2,strides=(2,2), padding='same'))\n","\n","\n","\n","# Add new layers\n","gender_model.add(Flatten())\n","gender_model.add(Dense(FC , activation='relu'))\n","gender_model.add(layers.Dropout(.2))\n","gender_model.add(Dense(FC , activation='relu'))\n","gender_model.add(layers.Dropout(.2))\n","gender_model.add(Dense(FC, activation='relu'))\n","gender_model.add(layers.Dropout(.2))\n","gender_model.add(Dense(E, activation='sigmoid'))\n","\n","gender_model.summary()"],"metadata":{"id":"YHiXPfGI7KP0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gender_model.compile(optimizer=Adam(adam),\n","              loss='binary_crossentropy'\n","              ,metrics=['accuracy'])"],"metadata":{"id":"NFi3kpSY7OXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lrd = ReduceLROnPlateau(monitor = 'val_loss',\n","                        patience = patience,\n","                        verbose = verbose ,\n","                        factor = factor,\n","                        min_lr = min_lr)\n","\n","mcp = ModelCheckpoint('model.h5')\n","\n","es = EarlyStopping(verbose=verbose, patience=patience)"],"metadata":{"id":"Wxq7gcUa7Rhu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%time\n","hist = gender_model.fit_generator(generator=train_generator,\n","                           validation_data=validation_generator,\n","                           steps_per_epoch=steps_per_epoch,\n","                           validation_steps=validation_steps,\n","                           epochs=epochs,\n","                           callbacks=[lrd, mcp, es])"],"metadata":{"id":"w7Q60sPW7VHK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After Train"],"metadata":{"id":"kKCd4MYn6yQ7"}},{"cell_type":"code","source":["predicted_ages = np.squeeze(model.predict(test_images))\n","true_ages = test_images.labels\n","\n","rmse = np.sqrt(age_model.evaluate(test_images, verbose=0))\n","print(\"     Test RMSE: {:.5f}\".format(rmse))\n","\n","r2 = r2_score(true_ages, predicted_ages)\n","print(\"Test R^2 Score: {:.5f}\".format(r2))"],"metadata":{"id":"iORDUGol56Xo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["null_rmse = np.sqrt(np.sum((true_ages - np.mean(true_ages))**2) / len(true_ages))\n","print(\"Null/Baseline Model Test RMSE: {:.5f}\".format(null_rmse))"],"metadata":{"id":"YItze0BM58jN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_image = '/content/drive/MyDrive/AI/AI_Project/FaceTest/test1.jpg'\n","image = tf.keras.preprocessing.image.load_img(test_image, target_size=(120,120))\n","\n","input_arr = np.array([tf.keras.preprocessing.image.img_to_array(image)]).astype('float32') / 255\n","predictions = age_model.predict(input_arr)\n","\n","X = tf.keras.utils.img_to_array(image)\n","X = np.expand_dims(X, axis=0)\n","\n","images = np.vstack([X])\n","classes = gender_model.predict(images, batch_size=1)\n","\n","plt.figure()\n","plt.imshow(image)\n","\n","predicted_age = predictions[0][0].astype(np.int32).astype(str)\n","actual_age = str(25)\n","\n","plt.title(\"Age And Gender Prediction\")\n","\n","print('Predicted: ' + predicted_age + '\\n' +\n","         'Actual: ' + actual_age + '\\n')\n","if classes[0]<0.5:\n","    print(\"This is a male\")\n","else:\n","    print( \"This  is a female\")\n","\n","plt.show()"],"metadata":{"id":"F3385a-o5_Oj"},"execution_count":null,"outputs":[]}]}